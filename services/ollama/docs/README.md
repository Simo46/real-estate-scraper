# Ollama Service Tests

## ğŸ“‹ Test disponibili

### ğŸ”— Integration Tests
Test di integrazione con API Gateway e servizi correlati.

```bash
# Esegui dalla directory del servizio
cd services/ollama
npm install
npm run test:integration
```

### ğŸ”— Complete Integration Tests
Test di integrazione completi end-to-end.

```bash
npm run test:integration:complete
```

### âš¡ Performance Monitoring
Test di performance e monitoring delle risorse.

```bash
npm run test:performance
```

### ğŸ“Š System Monitoring
Script di monitoring continuo del sistema Ollama.

```bash
npm run monitor
```

### ğŸ§ª Test Suite Completa
Esegue tutti i test in sequenza.

```bash
npm run test:all
```

## ğŸš€ Prerequisiti

### 1. Servizio Ollama attivo
Il servizio Ollama deve essere in esecuzione su `http://localhost:11434`.

```bash
# Avvia Ollama (dalla root del progetto)
docker-compose up ollama
```

### 2. API Gateway attivo
Per i test di integrazione, l'API Gateway deve essere attivo su `http://localhost:3000`.

```bash
# Avvia API Gateway (dalla root del progetto)
docker-compose up api-gateway
```

## ğŸ“Š Cosa testano

### Integration Tests
- âœ… Connessione diretta a Ollama
- âœ… Health check del servizio
- âœ… DisponibilitÃ  modelli
- âœ… Integrazione con API Gateway
- âœ… Performance baseline

### Performance Tests
- âœ… Tempi di risposta
- âœ… Utilizzo memoria
- âœ… Throughput richieste
- âœ… StabilitÃ  sotto carico

### Monitoring
- âœ… Status servizio in tempo reale
- âœ… Utilizzo risorse
- âœ… Log degli errori
- âœ… Alerting automatico

## ğŸ¯ Risultati attesi

### Integration Tests
```
ğŸ§ª Starting Ollama Integration Tests
âœ… Ollama health check: 200
âœ… Available models: 1
âœ… API Gateway health: 200
âœ… Response time: 150ms
ğŸ“Š Test Results: 4/4 passed
```

### Performance Tests
```
âš¡ Ollama Performance Monitor
ğŸ“Š Memory usage: 2.1GB
ğŸ”„ Active connections: 5
â±ï¸  Average response time: 120ms
âœ… All metrics within normal range
```

## ğŸ› ï¸ Troubleshooting

### Ollama non raggiungibile
```bash
# Verifica che Ollama sia attivo
curl http://localhost:11434/
```

### Modelli non disponibili
```bash
# Lista modelli disponibili
curl http://localhost:11434/api/tags
```

### Errori di integrazione
```bash
# Verifica logs
docker-compose logs ollama
docker-compose logs api-gateway
```

## ğŸ”„ Integrazione CI/CD

I test possono essere integrati in pipeline CI/CD:

```bash
#!/bin/bash
# CI script per test Ollama
cd services/ollama

# Installa dipendenze
npm ci

# Esegui test suite
npm run test:all

# Verifica performance
npm run test:performance
```

---

*Test interni al servizio Ollama seguendo le best practices architetturali* ğŸ—ï¸
